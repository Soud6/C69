import os
import streamlit as st
import pickle
import time
import fitz 
import pandas as pd
from langchain_anthropic import ChatAnthropic
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS

# Manually set the API key
ANTHROPIC_API_KEY = "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"

# UI Enhancements
st.set_page_config(page_title="AKKuretBot: Data Analytics Tool", page_icon="üìä", layout="wide")
st.markdown("""
    <style>
    .main {background-color: #FF5A5F; padding: 20px; border-radius: 10px;}
    .stButton > button {background-color: #FC642D; color: white; border-radius: 10px;}
    .stSidebar {background-color: #FFB400; padding: 20px; border-radius: 10px;}
    .stTextInput > div > div > input {border: 2px solid #FF385C; border-radius: 8px;}
    .stRadio > label {color: #484848; font-weight: bold;}
    </style>
""", unsafe_allow_html=True)

st.title("üöÄ AKKuretBot: Data Analytics Research Tool")
st.sidebar.title("üîç Select Your AI Model")

# User selects LLM model
llm_option = st.sidebar.radio("Choose an LLM", ["Claude-3-7-Sonnet", "Claude-3-5-Haiku", "Hugging Face Model"], index=0)

if llm_option == "Claude-3-7-Sonnet":
    llm = ChatAnthropic(
        model="claude-3-7-sonnet-20250219",
        temperature=0.7,
        max_tokens=500,
        anthropic_api_key=ANTHROPIC_API_KEY
    )
elif llm_option == "Claude-3-5-Haiku":
    llm = ChatAnthropic(
        model="claude-3-5-haiku-20241022",
        temperature=0.7,
        max_tokens=500,
        anthropic_api_key=ANTHROPIC_API_KEY
    )
else:
    st.sidebar.warning("ü§ñ Hugging Face model integration coming soon!")
    llm = None

st.sidebar.title("üìÇ Upload Files")

# Upload multiple PDF and Excel files
uploaded_files = st.sidebar.file_uploader("Upload Files (PDF/Excel)", accept_multiple_files=True, type=["pdf", "xlsx", "xls"])
process_files_clicked = st.sidebar.button("üöÄ Process Files")
file_path = "faiss_store.pkl"

main_placeholder = st.empty()

if process_files_clicked and uploaded_files and llm:
    docs = []
    for uploaded_file in uploaded_files:
        if uploaded_file.type == "application/pdf":
            # Read PDF text
            pdf_reader = fitz.open(stream=uploaded_file.read(), filetype="pdf")
            text = "\n".join([page.get_text("text") for page in pdf_reader])
        elif uploaded_file.type in ["application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", "application/vnd.ms-excel"]:
            # Read Excel file
            df = pd.read_excel(uploaded_file)
            text = df.to_string()
        
        # Split text into smaller chunks for better embeddings
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=100, separators=['\n\n', '\n', '.', ',']
        )
        file_docs = text_splitter.create_documents([text], metadatas=[{"source": uploaded_file.name} for _ in range(len(text_splitter.split_text(text)))])
        docs.extend(file_docs)
    
    main_placeholder.success("‚úÖ Files Processed Successfully!")
    embeddings = HuggingFaceEmbeddings()
    vectorstore = FAISS.from_documents(docs, embeddings)
    
    # Save FAISS index
    with open(file_path, "wb") as f:
        pickle.dump(vectorstore, f)
    
    time.sleep(2)

st.subheader("üí° Ask a Data Analytics Question:")
query = st.text_input("Type your query here...")
if query and llm:
    if os.path.exists(file_path):
        with open(file_path, "rb") as f:
            vectorstore = pickle.load(f)
            retriever = vectorstore.as_retriever(search_kwargs={"k": 3})  # Retrieve top 3 matches
            chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=retriever)
            result = chain({"question": query}, return_only_outputs=True)
            
            st.markdown("### ü§ñ Answer")
            answer_text = result.get("answer", "No answer found.")
            st.success(answer_text)
            
            # Display sources with similarity scores
            sources = result.get("sources", "")
            if sources:
                st.subheader("üìå Sources and Confidence Scores:")
                for source in sources.split("\n"):
                    st.write(f"üîπ {source}")
                
            # Judgment panel for optimized results
            st.subheader("üìù Rate the Response:")
            rating = st.radio("How helpful was the answer?", ("Excellent", "Good", "Average", "Poor"))
            st.button("Submit Rating")
            
            # Provide an option to refine results
            refine_query = st.text_input("üîÑ Refine your question for better accuracy:")
            if refine_query:
                result = chain({"question": refine_query}, return_only_outputs=True)
                st.success(result.get("answer", "No answer found."))
